{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9abaa34c-5200-4c4b-bace-be89b77614ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import re,os\n",
    "import glob, traceback\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa6d38a-5f14-4252-9615-f0b75a45c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_keywords_map= {\n",
    "'tobacco' : ['nicotine', 'tobacco', 'cigarette', 'cigarrette', 'cigar', 'bidis', 'snuff'],\n",
    "'alcohol' : ['liquo', 'beer', 'wine'],\n",
    "'cannabinoids' : ['marijuana', 'blunt', 'dope', 'ganja', 'grass', 'herb', 'joint', 'bud', 'mary jane', 'pot', 'reefer', 'green', 'trees', 'smoke', 'sinsemilla', 'skunk', 'weed','hashish', 'boom', 'gangster', 'hash', 'hash oil', 'hemp'],\n",
    "'opioids' : ['heroin', 'smack', 'horse', 'brown sugar', 'dope', \n",
    "             # 'H',\n",
    "             'junk', 'skag', 'skunk', 'white horse', 'China white','opium', 'laudanum', 'paregoric', 'big O', 'black stuff', 'block', 'gum', 'hop'],\n",
    "'stimulants': ['cocaine', 'hydrochloride', 'blow', 'bump',\n",
    "               # 'C',\n",
    "                'candy', 'Charlie', 'coke', 'crack', 'flake', 'rock', 'snow', 'toot','amphetamine', 'Biphetamine', 'Dexedrine', 'bennies', 'black beauties', 'crosses', 'hearts', 'LA turnaround', 'speed', 'truck drivers', 'uppers','methamphetamine', 'Desoxyn','meth', 'ice', 'crank', 'chalk', 'crystal', 'fire', 'glass', 'go fast', 'speed'],\n",
    "'club_drugs':['mdma', 'ecstasy', 'adam', 'clarity', 'eve', \"lover's speed\", 'peace', 'uppers','flunitrazepam', 'rohypnol', 'forget-me pill', 'mexican valium', 'r2', 'roach', 'roche', 'roffles', 'roofinol', 'rope', 'rophies','ghb', 'Gamma-hydroxybutyrate', \n",
    "              # 'G',\n",
    "              'Georgia home boy', 'grievous bodily harm', 'liquid ecstasy', 'soap', 'scoop', 'goop', 'liquid X'],\n",
    "'dissociative_drugs':['ketamine', 'Ketalar SV', 'cat Valium',\n",
    "                      # 'K',\n",
    "                      'Special K', 'vitamin K','pcp and analogs', 'phencyclidine' 'angel dust', 'boat', 'hog', 'love boat', 'peace pill','salvia divinorum', 'salvia', 'shepherdessâ€™s herb', 'maria pastora', 'magic mint', 'sally-d','dextromethorphan', 'dxm',  'robotripping', 'robo', 'triple'],\n",
    "'hallucinogens':['lsd','Lysergic acid diethylamide', 'acid', 'blotter', 'cubes', 'microdot', 'yellow sunshine', 'blue heaven', 'mescaline', 'Buttons', 'cactus', 'mesc', 'peyote', 'psilocybin', 'Magic mushrooms', 'purple passion', 'shrooms', 'little smoke'],\n",
    "'other_compounds':['anabolic_steroids', 'Anadrol', 'Oxandrin', 'Durabolin', 'Depo-Testosterone', 'Equipoise', 'roids', 'juice', 'gym candy', 'pumpers','inhalants', 'Solvents', 'paint thinners', 'gasoline', 'glues', 'gasses', 'butane', 'propane', 'aerosol propellants', 'nitrous oxide',  'nitrites' ,'isoamyl', 'isobutyl', 'cyclohexyl','laughing gas', 'poppers', 'snappers', 'whippets'],\n",
    "'prescription_medications':['cns_depressants', 'stimulants', 'opioid pain relievers', 'OxyContin','Oxycodone', 'Vicodin', 'Norco', 'Lortab', 'Hydrocodone', 'Acetaminophen', 'Percocet ', 'Oxycodone', 'Acetaminophen','Tramadol','Codeine','Morphine','Methadone','Demerol', 'meperidine','Acetaminophen','Tylenol', 'Excedrin', 'Vanquish','Aspirin', 'Bayer', 'Bufferin', 'Ecotrin', 'Excedrin', 'Vanquish','Diclofenac', 'Voltaren Gel','Ibuprofen', 'Advil', 'Motrin IB','Naproxen', 'Aleve']\n",
    "}\n",
    "\n",
    "columns_to_check = list(drug_keywords_map.keys())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc894643-a3f2-4a38-85fc-028feb893bc3",
   "metadata": {},
   "source": [
    "## 1. Read all csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4af246fe-7cc4-4c27-8b36-c5ab017e4e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 -->  (314802, 13)\n",
      "02 -->  (262253, 13)\n",
      "03 -->  (243710, 13)\n",
      "04 -->  (264268, 13)\n",
      "05 -->  (284107, 13)\n",
      "06 -->  (287253, 13)\n",
      "07 -->  (223417, 13)\n",
      "08 -->  (200202, 13)\n",
      "09 -->  (194789, 13)\n",
      "10 -->  (177181, 13)\n",
      "11 -->  (188957, 13)\n",
      "12 -->  (307397, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2948336, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = []\n",
    "months = [1, 2, 3, 4, 5,6, 7, 8, 9, 10, 11, 12]\n",
    "#months = [1, 2]\n",
    "\n",
    "# for month in range(10, 13):\n",
    "for month in months:\n",
    "    mo = f\"{month:02d}\"\n",
    "    files = glob.glob('/data2/julina/scripts/tweets/2019/'+mo+'/pred/dm/*.csv')\n",
    "    dfs = []\n",
    "    for csv_file in files:\n",
    "        try:\n",
    "            # print(csv_file)\n",
    "            a = pd.read_csv(csv_file)\n",
    "            a = a.loc[:, ~a.columns.str.match('Unnamed')]\n",
    "            a = a.loc[:, ~a.columns.str.match('label')]\n",
    "            a = a.loc[:, ~a.columns.str.match('text_y')]\n",
    "            dfs.append(a)\n",
    "        except:\n",
    "            print(f' failed for file : {csv_file}')\n",
    "            pass\n",
    "    mo_df = pd.concat(dfs, ignore_index=True)\n",
    "    mo_df['date'] = pd.to_datetime('2020-' + mo)\n",
    "    print(mo, '--> ', mo_df.shape)\n",
    " \n",
    "    all_df.append(mo_df)\n",
    "dff = pd.concat(all_df, ignore_index=True)\n",
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61729f28-bb78-44ed-8118-2e6d85dca378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2799726, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.drop_duplicates(subset=['text', 'created_at'], inplace=True)\n",
    "# dff.drop_duplicates(subset=['text', 'date'], inplace=True)\n",
    "\n",
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be35c242-ad26-4d77-9905-3f57d5e53fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['is_teenage'] = dff.apply(lambda row: 1 if row['age'] == '<=18' else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7c23ae3-aa48-4e76-9775-0de4b81da1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword, words in drug_keywords_map.items():\n",
    "    pattern = fr'\\b(?:{\"|\".join(words)})\\b'\n",
    "    dff[keyword] = dff['text'].str.contains(pattern, case=False).astype(int)\n",
    "dff['drug_type'] = dff[columns_to_check].apply(lambda row: [col for col, val in zip(columns_to_check, row) if val == 1], axis=1)\n",
    "dff.drop(columns_to_check, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5b9246c-da9e-442f-9f63-edae30d47c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2799726, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce7c06e4-a37c-4cfe-9bf7-74cf156bb1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv('/data2/julina/scripts/tweets/cleaned_data_by_year/2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0324420a-7d2f-43c1-a203-74235987a3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>description</th>\n",
       "      <th>DrugAbuse</th>\n",
       "      <th>lang</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>org</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sent_score</th>\n",
       "      <th>date</th>\n",
       "      <th>is_teenage</th>\n",
       "      <th>drug_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1214331878381170694</td>\n",
       "      <td>Mon Jan 06 23:44:15 +0000 2020</td>\n",
       "      <td>nova jut give nose boop first ever boop proud ...</td>\n",
       "      <td>1034618872413020161</td>\n",
       "      <td>geralt hm fuck</td>\n",
       "      <td>lonioiHetairoi</td>\n",
       "      <td>Knell - ðŸ‡¨ðŸ‡¦ 26 - Pan - NB - they/them Nintendo ...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>male</td>\n",
       "      <td>30-39</td>\n",
       "      <td>non-org</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                      created_at  \\\n",
       "0  1214331878381170694  Mon Jan 06 23:44:15 +0000 2020   \n",
       "\n",
       "                                                text              user_id  \\\n",
       "0  nova jut give nose boop first ever boop proud ...  1034618872413020161   \n",
       "\n",
       "             name     screen_name  \\\n",
       "0  geralt hm fuck  lonioiHetairoi   \n",
       "\n",
       "                                         description  DrugAbuse lang gender  \\\n",
       "0  Knell - ðŸ‡¨ðŸ‡¦ 26 - Pan - NB - they/them Nintendo ...          1   en   male   \n",
       "\n",
       "     age      org sentiment  sent_score       date  is_teenage drug_type  \n",
       "0  30-39  non-org       neu         0.0 2020-01-01           0        []  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dff.sample(10)[['text', 'sentiment', 'sent_score']]\n",
    "dff.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120d9d6-edc7-47d2-b8fb-1f790f033680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8ebeb-77bb-46a6-9354-bda8064af7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09769175-b973-4332-832c-1a202483afe8",
   "metadata": {},
   "source": [
    "## Cohort I: Teenage and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e7e40158-d51e-4c7a-90b5-2296dea6a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2592262/4280701966.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tf_df['cleaned_text'] = tf_df['text'].apply(lambda x: ' '.join(['' if word.lower() in words_to_remove else word for word in x.split()]))\n"
     ]
    }
   ],
   "source": [
    "words_to_remove = ['httpurl', 'hashtag', 'user']\n",
    "tf_df['cleaned_text'] = tf_df['text'].apply(lambda x: ' '.join(['' if word.lower() in words_to_remove else word for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a07500b7-e3f1-4c24-92af-b61e8915a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_df.shape\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), max_df=0.75, min_df=0.001, use_idf=True)\n",
    "posts_tfidf_bow = vectorizer.fit_transform(tf_df['cleaned_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f2c08bfd-e023-41e1-99fb-2656b5ede7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=LatentDirichletAllocation(n_components=10,learning_method='online',random_state=42,max_iter=1) \n",
    "lda_top=lda_model.fit_transform(posts_tfidf_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c2481b33-6e82-46c3-be31-287e84a29a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "still think covid tell alcohol hit someone first tequila enough little really bro break ever toxic long different away have \n",
      "\n",
      "Topic 1: \n",
      "drinking wine me drink cocaine water watch would shot 2021 cold go best eat hot mom take 20 care go get \n",
      "\n",
      "Topic 2: \n",
      "smoke blunt smoking feel cigarette try leave good girl amp make bottle christmas see hide he everyday put say shit \n",
      "\n",
      "Topic 3: \n",
      "drunk get get drunk love know stop coke lmfao night do bitch slow talk taste help lit whole walk actually body \n",
      "\n",
      "Topic 4: \n",
      "weed smoke please even fuck people glass start sleep smoke weed get day fun take always let bar drink drunk damn \n",
      "\n",
      "Topic 5: \n",
      "pain look tonight time turn today wtf every also energy hold light tree house share deserve 2020 many go almost \n",
      "\n",
      "Topic 6: \n",
      "it well never come one keep get could vote sex ask cigarettes head chill hope everything listen room eye high \n",
      "\n",
      "Topic 7: \n",
      "high need get beer right give year new thing drink wine drug get high guy nobody one work make end really \n",
      "\n",
      "Topic 8: \n",
      "drink crack much blink vaccine this coffee man tire loudlycryingface get since red miss happy call yes be maybe wake \n",
      "\n",
      "Topic 9: \n",
      "not can can not nose drunk weed lol way without drink friend liquor lmao get anyone find drunk girl home know everyone \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vocab = vectorizer.get_feature_names()\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "     vocab_comp = zip(vocab, comp)\n",
    "     sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:20]\n",
    "     print(\"Topic \"+str(i)+\": \")\n",
    "     # print(sorted_words)\n",
    "     for t in sorted_words:\n",
    "        print(t[0], end=\" \")\n",
    "     print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45ecd4-68f3-40ea-9916-746b8c7db7e1",
   "metadata": {},
   "source": [
    "## Question: I am trying to do Thematic analysis in twitter data. This is a cohort from teenager female users. All the tweets are identified as drug abuse from our custom DL model. Now, I have 10 topics and associated keywords from LDA, however I cannot seems to get the themes. Can you identify unique themes from following LDA result: \n",
    "\n",
    "To derive themes from the LDA topics you've shared, it's important to analyze the clusters of related words within each topic and consider the context in which they might be used, especially given the specific cohort (teenage female users) and the context of drug abuse. Hereâ€™s a thematic analysis based on the keywords from each topic:\n",
    "\n",
    "### Theme 1: **Coping Mechanisms**\n",
    "- **Topic 0** mentions terms like \"still think covid\", \"alcohol\", \"tequila\", \"toxic\", \"break\", suggesting discussions about coping with stress or mental health issues using substances.\n",
    "- **Topic 5** involves \"pain\", \"energy\", \"light\", \"house\", \"deserve\", \"2020\", indicating a focus on emotional and physical states and perhaps the environment in which substance use occurs.\n",
    "- **Topic 6** includes words like \"keep\", \"hope\", \"chill\", \"eye\", \"high\", \"head\", reflecting a coping theme but with a more internal, contemplative approach.\n",
    "\n",
    "### Theme 2: **Social Contexts and Interactions**\n",
    "- **Topic 1** revolves around social settings with \"drinking\", \"wine\", \"drink\", \"shot\", \"mom\", \"eat\", indicating a social or familial context.\n",
    "- **Topic 3** has \"drunk\", \"love\", \"night\", \"talk\", \"bitch\", \"lit\", highlighting social interactions while under the influence, potentially at parties or gatherings.\n",
    "- **Topic 8** mentions \"drink\", \"crack\", \"coffee\", \"loudlycryingface\", \"miss\", \"happy\", showing a range of emotional responses in social settings.\n",
    "\n",
    "### Theme 3: **Substance Use and Effects**\n",
    "- **Topic 2** focuses on the act and routine of substance use: \"smoke\", \"blunt\", \"cigarette\", \"bottle\", \"hide\", indicating habitual use and perhaps efforts to conceal this behavior.\n",
    "- **Topic 4** highlights frequent substance use and its normalization: \"weed\", \"smoke\", \"smoke weed\", \"bar\", \"fun\", \"drunk\", suggesting a routine and social aspect of use.\n",
    "- **Topic 7** shows a focus on addiction and regular use: \"high\", \"get high\", \"beer\", \"drink\", \"drug\", emphasizing dependence and routine consumption.\n",
    "\n",
    "### Theme 4: **Reactions and Responses**\n",
    "- **Topic 3** and **Topic 9** contain reactions to substance use situations, with words like \"stop\", \"can not\", \"without\", \"know\", \"help\", indicating resistance, help-seeking, or refusal in certain scenarios.\n",
    "\n",
    "### Theme 5: **Lifestyle and Identity**\n",
    "- **Topic 9** again, with \"drunk girl\", \"home\", \"friend\", \"lol\", \"lmao\", highlights a casual take on substance use, possibly as a part of identity or social image.\n",
    "\n",
    "These themes encapsulate various aspects of substance use among teenage females as reflected in your data: coping with personal issues, socializing with peers, routine and normalized use, direct reactions to drug abuse situations, and the incorporation of substance use into their lifestyle and identity. Each theme provides a different lens through which to understand the discussions around drug abuse in the cohort, potentially guiding further qualitative analysis or intervention strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad14e60-151b-4487-b288-fbbe1c9c7d76",
   "metadata": {},
   "source": [
    "## Cohort II: Teenager and Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94238d43-619b-4130-bd55-6111e2a8139e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3904108/2326186899.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tm_df['cleaned_text'] = tm_df['text'].apply(lambda x: ' '.join(['' if word.lower() in words_to_remove else word for word in x.split()]))\n"
     ]
    }
   ],
   "source": [
    "words_to_remove = ['httpurl', 'hashtag', 'user']\n",
    "tm_df['cleaned_text'] = tm_df['text'].apply(lambda x: ' '.join(['' if word.lower() in words_to_remove else word for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62f718c8-4316-44d0-a8e4-04cb050a8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_df.shape\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), max_df=0.75, min_df=0.001, use_idf=True)\n",
    "posts_tfidf_bow = vectorizer.fit_transform(tm_df['cleaned_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cfa704e-0cfa-49c8-90aa-1ced202aad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=LatentDirichletAllocation(n_components=10,learning_method='online',random_state=42,max_iter=1) \n",
    "lda_top=lda_model.fit_transform(posts_tfidf_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "982ecc35-7dce-41a2-a8b6-65eb78cfef2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "wine new drink start tonight leave look this eat bottle end beer heroin every water smoke you fun game new year \n",
      "\n",
      "Topic 1: \n",
      "it blunt coke try get right buy life even nigga good weed vote red nobody kill tire energy taste happy \n",
      "\n",
      "Topic 2: \n",
      "pain drinking love drug much never still street coffee drink high say tree blink 2021 make trump take cold god \n",
      "\n",
      "Topic 3: \n",
      "high make year not people can cigarette lol can not say well bad drive upgrade fire liquor drink find smoke weed \n",
      "\n",
      "Topic 4: \n",
      "drink would me cocaine please vaccine time keep back lit watch someone damn smoke break alcohol long pay listen bring \n",
      "\n",
      "Topic 5: \n",
      "get high lmfao really come bar way get high see turn wine drink two also best since maybe loudlycryingface head something \n",
      "\n",
      "Topic 6: \n",
      "crack let bro go thing stop get one smoke talk tell mean ever chill another asf anyone know stay again \n",
      "\n",
      "Topic 7: \n",
      "smoke alcohol weed know smoking need amp nose smoke weed day hit fuck covid house put think always 2020 next guy \n",
      "\n",
      "Topic 8: \n",
      "beer shit hold slow yes first bitch shot lmao tequila be everyone many enough already body little as pack fix \n",
      "\n",
      "Topic 9: \n",
      "drunk take give get drunk get sleep glass call girl night today smoke without feel could last man pop christmas home \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vocab = vectorizer.get_feature_names()\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "     vocab_comp = zip(vocab, comp)\n",
    "     sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:20]\n",
    "     print(\"Topic \"+str(i)+\": \")\n",
    "     # print(sorted_words)\n",
    "     for t in sorted_words:\n",
    "        print(t[0], end=\" \")\n",
    "     print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df83b7-972d-496c-be29-c1f59019b6a1",
   "metadata": {},
   "source": [
    "To derive themes from the LDA topics for teenage male Twitter users discussing drug abuse, we analyze the keywords within each topic while focusing on the social and behavioral nuances specific to this demographic. Hereâ€™s a thematic breakdown based on the provided keywords:\n",
    "\n",
    "### Theme 1: **Substance Use Practices**\n",
    "- **Topic 0** includes \"wine\", \"drink\", \"beer\", \"heroin\", \"smoke\", indicating a variety of substances used, perhaps reflecting experimentation or social drinking and smoking.\n",
    "- **Topic 1** with \"blunt\", \"coke\", \"weed\", \"kill\", \"energy\", \"taste\", suggests active engagement with substances, possibly exploring effects and potency.\n",
    "- **Topic 5** and **Topic 6** both highlight habitual use with \"get high\", \"smoke\", \"drink\", \"bar\", \"chill\", portraying both the social setting and the routine nature of substance use.\n",
    "\n",
    "### Theme 2: **Social Interactions and Peer Influence**\n",
    "- **Topic 6** emphasizes social dynamics: \"let\", \"bro\", \"go\", \"talk\", \"tell\", \"mean\", \"chill\", \"asf\", reflecting the influence of peer relationships and conversations around drug use.\n",
    "- **Topic 8** also revolves around social settings with \"beer\", \"shot\", \"tequila\", \"bitch\", \"everyone\", indicating gatherings or parties where substance use is a shared activity.\n",
    "\n",
    "### Theme 3: **Coping with Stress and Challenges**\n",
    "- **Topic 0** and **Topic 4** show signs of using substances to cope or enhance experiences: \"new year\", \"fun\", \"game\", \"damn\", \"break\", \"long\", \"pay\", suggesting use in times of celebration or stress relief.\n",
    "- **Topic 2** with \"pain\", \"love\", \"drug\", \"cold\", \"god\", indicates an emotional or spiritual seeking, perhaps using substances to deal with personal pain or existential questions.\n",
    "\n",
    "### Theme 4: **Reactions to Societal and Personal Issues**\n",
    "- **Topic 3** and **Topic 7** reflect a mix of defiance and frustration with societal norms: \"can not\", \"bad\", \"fire\", \"fuck\", \"covid\", \"2020\", showing how external events like the pandemic influence substance use behaviors and attitudes.\n",
    "- **Topic 9** expresses immediate reactions and needs: \"drunk\", \"sleep\", \"feel\", \"last\", \"home\", emphasizing the direct impact of substances on mood and state of being.\n",
    "\n",
    "### Theme 5: **Identity and Lifestyle**\n",
    "- **Topic 7** with \"smoke weed\", \"always\", \"think\", \"next\", \"guy\", suggests that substance use is intertwined with personal identity and day-to-day life.\n",
    "- **Topic 4** and **Topic 5** show aspects of lifestyle maintenance through substance use: \"keep\", \"lit\", \"watch\", \"best\", \"loudlycryingface\", portraying how substance use is integrated into daily routines and social image.\n",
    "\n",
    "These themes provide insights into the complex ways in which teenage males discuss and engage with substance use, from social bonding and routine practices to coping mechanisms and reactions to personal and societal challenges. Each theme offers a lens to understand the subtleties of conversations around drug abuse, useful for further qualitative analysis or developing targeted interventions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a405a-8e53-4b1c-91eb-b5fb0854001e",
   "metadata": {},
   "source": [
    "## Cohort III: Adult and Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a24f3e2d-b47a-4c21-8549-11e5a71a8d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3904108/229630082.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  af_df['cleaned_text'] = af_df['text'].apply(lambda x: ' '.join(['' if word.lower() in words_to_remove else word for word in x.split()]))\n"
     ]
    }
   ],
   "source": [
    "words_to_remove = ['httpurl', 'hashtag', 'user']\n",
    "af_df['cleaned_text'] = af_df['text'].apply(lambda x: ' '.join(['' if word.lower() in words_to_remove else word for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "817c511e-6db9-473f-8c94-ab831854ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_df.shape\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), max_df=0.75, min_df=0.001, use_idf=True)\n",
    "posts_tfidf_bow = vectorizer.fit_transform(af_df['cleaned_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e212618-8537-43eb-bb99-5feb517aafa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=LatentDirichletAllocation(n_components=10,learning_method='online',random_state=42,max_iter=1) \n",
    "lda_top=lda_model.fit_transform(posts_tfidf_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb931f93-7af7-4be1-b727-b25eaa90ddf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "high love get please give watch weed fuck fun end start you 2021 lit get high amp lmao smoke always kill \n",
      "\n",
      "Topic 1: \n",
      "smoke weed crack would vote cocaine covid life shit smoke weed tell me bad anyone think holy room eye mind listen \n",
      "\n",
      "Topic 2: \n",
      "blunt come need know damn back nobody never lmfao friend loudlycryingface night wine get miss drink last biden taste tire \n",
      "\n",
      "Topic 3: \n",
      "not can can not talk even yes eat see drink well food drunk without wait everyone anxiety hide next white literally \n",
      "\n",
      "Topic 4: \n",
      "take drug liquor bar bottle coke leave street find house also amp wine nigga weed drink mean morning whole use \n",
      "\n",
      "Topic 5: \n",
      "pain stop time do drive drink way buy trump guy cigarette drunk coffee first take hold beer this slow reason \n",
      "\n",
      "Topic 6: \n",
      "alcohol keep man hit much amp bring away public toxic crazy litigation full fact dad governor feeling parent drink alcohol koolaid \n",
      "\n",
      "Topic 7: \n",
      "drink beer year new it try tequila bitch need call shot ever two get new year work old covid maybe again \n",
      "\n",
      "Topic 8: \n",
      "drunk get vaccine get drunk day thing tonight lol smoking really go sleep still one nose feel christmas good right today \n",
      "\n",
      "Topic 9: \n",
      "wine drinking glass let water every red put drink get election eligible break turn cold hear day light fine now \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vocab = vectorizer.get_feature_names()\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "     vocab_comp = zip(vocab, comp)\n",
    "     sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:20]\n",
    "     print(\"Topic \"+str(i)+\": \")\n",
    "     # print(sorted_words)\n",
    "     for t in sorted_words:\n",
    "        print(t[0], end=\" \")\n",
    "     print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaf63a6-7575-4186-8365-13b6953c56d7",
   "metadata": {},
   "source": [
    "## Cohort IV: Adult and Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa659f21-d392-4c1b-b2d1-700ebdb9b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_remove = ['httpurl', 'hashtag', 'user']\n",
    "am_df['cleaned_text'] = am_df['text'].apply(lambda x: ' '.join(['' if word.lower() in words_to_remove else word for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56631518-6447-4766-800e-64e95cd0f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_df.shape\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), max_df=0.75, min_df=0.001, use_idf=True)\n",
    "posts_tfidf_bow = vectorizer.fit_transform(am_df['cleaned_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef38f7-aecc-49ae-a650-175d9ade3f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=LatentDirichletAllocation(n_components=10,learning_method='online',random_state=42,max_iter=1) \n",
    "lda_top=lda_model.fit_transform(posts_tfidf_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18e7a3-664e-4bef-86fa-1c3a5864c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = vectorizer.get_feature_names()\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "     vocab_comp = zip(vocab, comp)\n",
    "     sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:20]\n",
    "     print(\"Topic \"+str(i)+\": \")\n",
    "     # print(sorted_words)\n",
    "     for t in sorted_words:\n",
    "        print(t[0], end=\" \")\n",
    "     print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c5b9b5-20c4-45e5-8b25-2445ae9828b0",
   "metadata": {},
   "source": [
    "## Cohort V: Org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab1b9c7b-df4d-48ca-9c9c-7c45c5f8eda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3904108/2608925739.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  is_org['cleaned_text'] = is_org['text'].apply(lambda x: ' '.join(['' if word.lower() in words_to_remove else word for word in x.split()]))\n"
     ]
    }
   ],
   "source": [
    "words_to_remove = ['httpurl', 'hashtag', 'user']\n",
    "is_org['cleaned_text'] = is_org['text'].apply(lambda x: ' '.join(['' if word.lower() in words_to_remove else word for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b568b98-f2c1-4349-848d-d6581956c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_df.shape\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), max_df=0.75, min_df=0.001, use_idf=True)\n",
    "posts_tfidf_bow = vectorizer.fit_transform(is_org['cleaned_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85810058-d41f-4bda-abab-95929574dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=LatentDirichletAllocation(n_components=10,learning_method='online',random_state=42,max_iter=1) \n",
    "lda_top=lda_model.fit_transform(posts_tfidf_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c631a46-8fbc-4f20-affb-638c1e325ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "wine take glass not can buy drink leave can not beer water tree next user liquidation come wineglass short one beermug \n",
      "\n",
      "Topic 1: \n",
      "smoking amp night red tonight wine last end bar guy give another pay white lose life pipe start drink world \n",
      "\n",
      "Topic 2: \n",
      "high thing alcohol upgrade eat low new be food use chinese sleep drink die time mean report covid alcoholic due \n",
      "\n",
      "Topic 3: \n",
      "drunk one say keep love joe drive get go break take sell county trump home joe biden game heroin ever house \n",
      "\n",
      "Topic 4: \n",
      "smoke crack go vote get know it look right try lol trump slow see blunt now money cigar walk run \n",
      "\n",
      "Topic 5: \n",
      "weed drink day nose first could state long hit call 2021 get drunk smoke tequila get drunk play listen voter time \n",
      "\n",
      "Topic 6: \n",
      "drinking 2020 year smoke christmas fire gun every good stop open eligible best well do watch without happy wine bad \n",
      "\n",
      "Topic 7: \n",
      "cocaine coke think would biden get cigarette much man let hunter liquor smoke fuck you via way really high kill \n",
      "\n",
      "Topic 8: \n",
      "drug vaccine street covid million feel help need get shit alcohol mitch free something stay must business say month drink \n",
      "\n",
      "Topic 9: \n",
      "beer pain hold election bottle in hold beer turn coffee yes maine show public and order liquid light new big covid19 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vocab = vectorizer.get_feature_names()\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "     vocab_comp = zip(vocab, comp)\n",
    "     sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:20]\n",
    "     print(\"Topic \"+str(i)+\": \")\n",
    "     # print(sorted_words)\n",
    "     for t in sorted_words:\n",
    "        print(t[0], end=\" \")\n",
    "     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db386c-954a-43eb-bb3b-5c417b383a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
